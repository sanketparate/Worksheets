{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><B><U>WEB SCRAPING</U></B><BR>\n",
    "WORKSHEET-1</CENTER>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<B>In Q1 to Q9, only one option is correct, Choose the correct option:</B><br>\n",
    "1.\tWhich of the following extracts information from user generated content?<br>\n",
    "A) Java script tagging \t\t\tB) Web scraping\n",
    "C) A/B testing\t\t\t\tD) MROCs\n",
    "\n",
    "Answer: B) Web Scraping<br>\n",
    "\n",
    "2.\tWhich of the following is not a web scraping library in python?<br>\n",
    "A) selenium\t\t\t\tB) Beautiful soup\n",
    "C) Requests\t\t\t\tC) scrapy\n",
    "\n",
    "Answer: C) Requests\n",
    "\n",
    "3.\tSelenium tests __________?<br>\n",
    "A) Browser based applications\t\tB) DOS applications\n",
    "C) GUI applications\t\t\tD) All of the above\n",
    "\n",
    "Answer: A) Browser based applications\n",
    "\n",
    "4.\tTask of crawling is performed by a complex software which is known as:<br>\n",
    "A) Scraper\t\t\t\tB) Crawler\n",
    "C) Boat\t\t\t\t\tD) Spider\n",
    "\n",
    "Answer:D) Spider\n",
    "\n",
    "5.\tWhich of the following commands is used to access name of a tag in Beautiful Soup?<br>\n",
    "A) tag.attrs\t\t\t\tB) tag.name\n",
    "C) tag,id\t\t\t\tC) tag[‘id’]\n",
    "\n",
    "Answer: B) tag.name\n",
    "\n",
    "6.\tWhich of the following is the default parser in Beautiful Soup?<br>\n",
    "A) html.parser\t\t\t\tB) html5lib\n",
    "C) lxml\t\t\t\t\tD) lxml-xml\n",
    "\n",
    "Answer: A) html.parser\n",
    "\n",
    "7.\tIn selenium the webdriver is used to?<br>\n",
    "A) design a test using selenese\n",
    "B) test a web application on firefox only\n",
    "C) execute tests on HtmlUnit browser\n",
    "D) to download any content from a webpage\n",
    "\n",
    "Answer: C) execute tests on HtmlUnit browser\n",
    "\n",
    "8.\tIn selenium, driver.find_elements_by_xpath(‘given xpath’) returns:<br>\n",
    "A) the first webelement associated with the ‘given xpath’\n",
    "B) the url of first webelement associated with the ‘given xpath’\n",
    "C) the list of all webelements associated with the ‘given xpath’\n",
    "D) all the attributes of the first webelement associated with the ‘given xpath’\n",
    "\n",
    "Answer:\n",
    "\n",
    "9.\tThe script ‘window.scrollBy(0,a) scrolls the webpage by?<br>\n",
    "A) ‘a’ number of horizontal spaces\n",
    "B) ‘a’ number of lines\n",
    "C) ‘a’ number of pixels horizontally\n",
    "D) ‘a’ number of pixels vertically\n",
    "\n",
    "Answer: C) 'a' number of pixels horizontally\n",
    "\n",
    "<b>In Q10, more than one options are correct, Choose all the correct options:</b><br>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10.\tWhich of the following is(are) tags of HTML?<br>\n",
    "A) <a>\t\t\t\t\tB) <b>\n",
    "C) <image>\t\t\t\tD) <href>\n",
    "\n",
    "Answer: A), B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q11 to Q13 are subjective answer type questions, Answer them briefly.</b><br>\n",
    "11.\tWhat is the main difference between a web scraper and a web crawler?<br>\n",
    "Answer: **Web crawlers** work by browsing to a series of webpages and analyzing their contents for links to other webpages. The links to the other webpages are then followed and searched for more links. The process of following and indexing these links is referred to as *crawling*. Whereas, **web scraping** captures the content of those pages which can then be analyzed to reveal more information about the crawled pages. For eg: *search engines* use *crawling* and *web aggregators* use *scraping*.\n",
    "\n",
    "12.\tWhat is ‘robots.txt’ file? What is the use of ‘robots.txt’ file?<br>\n",
    "Answer: A **robots.txt** file tells crawlers which pages or files the crawler can or can't request from your site. This is used mainly to avoid overloading your site with requests. Robots.txt is not a mechanism of keeping your weppage out of the reach of crawlers or spiders. Robots.txt is mainly used for traffic management of a webpage.\n",
    "\n",
    "13.\tWhat are static and dynamic web pages?<br>\n",
    "Answer: <br>\n",
    "**Static Web pages:** Static Web pages are very simple. They are written in languages such as HTML, JavaScript, CSS, etc. For static web pages when a server receives a request for a web page, then the server sends the response to the client without doing any additional process. And these web pages are seen through a web browser. In static web pages, Pages will remain the same until someone changes it manually. eg: Blogs, Documentation sites.<br>\n",
    "\n",
    "     **Dynamic Web Pages:** Dynamic Web Pages are written in languages such as CGI, AJAX, ASP, ASP.NET, etc. In dynamic web pages, the Content of pages is different for different visitors. It takes more time to load than the static web page. Dynamic web pages are used where the information is changed frequently. eg: stock prices, weather information, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q14 and Q15 are programming practice questions. Solve it using JUPYTER NOTEBOOK and paste the solution in your answer sheets.</b>\n",
    "14.\tWrite a python program to check whether a webpage contains a title or not.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Flipkart: The One-stop Shopping Destination</h1>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function for scraping the title\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)                          # Crawling the url\n",
    "    except HTTPError as e:                           # If url link is not active return None  \n",
    "        return None\n",
    "    try:\n",
    "        soup = BeautifulSoup(html.read(), \"lxml\")    # Reading the html script of webpage\n",
    "        title = soup.body.h1                         # Scraping the title\n",
    "    except AttributeError as e:                      # If title is not present then return None\n",
    "        return None\n",
    "    return title\n",
    "    \n",
    "    title = getTitle(url)\n",
    "    if title == None:\n",
    "        return \"Title could not be found\"\n",
    "    else:\n",
    "        return title\n",
    "\n",
    "print(getTitle(\"https://www.flipkart.com/\"))\n",
    "print(getTitle(\"https://www.myntra.com/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.\tWrite a python program to access the search bar and search button on images.google.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "# Activating the web browser\n",
    "DRIVER_PATH=\"C:\\\\Users\\\\SANKET\\\\Music\\\\Fliprobo\\\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "\n",
    "# Opening google images website\n",
    "driver.get('https://images.google.com/')\n",
    "\n",
    "# Finding the search bar using it's xpath\n",
    "search_bar = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/div/div[2]/input')\n",
    "# Inputing \"banana\" keyword to search banana images\n",
    "search_bar.send_keys(\"banana\")  \n",
    " # Finding the xpath of search button\n",
    "search_button = driver.find_element_by_xpath('//*[@id=\"sbtc\"]/button') \n",
    "# Clicking the search button\n",
    "search_button.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closing the web browser\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
